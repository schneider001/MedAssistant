{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV, RandomizedSearchCV\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Dict\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import model_functions as mf \n",
    "# import lightgbm\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import warnings\n",
    "import gc\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "from collections import Counter\n",
    "import subprocess\n",
    "from sklearn.utils import shuffle\n",
    "# from pandas import shuffle\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 500)\n",
    "pd.set_option(\"display.width\", 500)\n",
    "pd.set_option(\"display.max_columns\", 500)\n",
    "\n",
    "current_user = os.environ.get('USER')\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.random.seed(42)\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import yaml\n",
    "\n",
    "# with open('/configs/config.yaml', 'r') as f:\n",
    "#     config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('..')\n",
    "\n",
    "df= pd.read_csv('dataset.csv')\n",
    "df = shuffle(df,random_state=42)\n",
    "\n",
    "\n",
    "sym_des = pd.read_csv('symptom_Description.csv')\n",
    "sym_pre = pd.read_csv('symptom_precaution.csv')\n",
    "df1 = pd.read_csv('Symptom-severity.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    df[col] = df[col].str.replace('_',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df.columns\n",
    "data = df[cols].values.flatten()\n",
    "\n",
    "s = pd.Series(data)\n",
    "s = s.str.strip()\n",
    "s = s.values.reshape(df.shape)\n",
    "\n",
    "df = pd.DataFrame(s, columns=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Symptom'] = df1['Symptom'].str.replace('_',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = df.values\n",
    "symptoms = df1['Symptom'].unique()\n",
    "\n",
    "for i in range(len(symptoms)):\n",
    "    vals[vals == symptoms[i]] = df1[df1['Symptom'] == symptoms[i]]['weight'].values[0]\n",
    "    \n",
    "d = pd.DataFrame(vals, columns=cols)\n",
    "\n",
    "d = d.replace('dischromic  patches', 0)\n",
    "d = d.replace('spotting  urination',0)\n",
    "df = d.replace('foul smell of urine',0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiclass vs multiclassova Objective\n",
    "lgb_params = {\n",
    "        \"objective\": \"multiclassova\",\n",
    "        # \"metric\": \"cross_entropy\",\n",
    "        \"max_bin\": 5,\n",
    "        \"max_depth\" : 2,\n",
    "        \"num_leaves\": 5,\n",
    "        \"min_data_in_leaf\" : 5,\n",
    "        \"learning_rate\": 0.2,\n",
    "        \"bagging_fraction\": 0.7,\n",
    "        \"feature_fraction\": 0.5,\n",
    "        \"bagging_seed\": 2018,\n",
    "        \"verbosity\": -1\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.iloc[:,1:].values\n",
    "labels = df['Disease'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3936, 17) (984, 17) (3936,) (984,)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(data, labels, train_size = 0.8,random_state=42)\n",
    "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Dict\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import lightgbm\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TrainTestData:\n",
    "    X_train: pd.DataFrame\n",
    "    X_valid: pd.DataFrame\n",
    "    y_train: pd.Series\n",
    "    y_valid: pd.Series\n",
    "\n",
    "\n",
    "class LGBModel:\n",
    "    \n",
    "    def __init__(self, lgb_params: Dict, test_size: float=.33):\n",
    "        self.test_size = test_size\n",
    "        self.lgb_params = lgb_params\n",
    "        \n",
    "        self.model = None       \n",
    "    \n",
    "    def _split_train_test(self, X: pd.DataFrame, y: pd.Series) -> TrainTestData:\n",
    "        X_train, X_valid, y_train, y_valid = \\\n",
    "                    train_test_split(X, y, test_size=self.test_size, random_state=42)\n",
    "        \n",
    "        return TrainTestData(X_train, X_valid, y_train, y_valid)\n",
    "    \n",
    "    def predict(self, X: pd.DataFrame) -> np.array:\n",
    "        return self.model.predict_proba(X)[:, 1]\n",
    "    \n",
    "    def calc_auc(self, X: pd.DataFrame, y: pd.Series) -> float:\n",
    "        predictions = self.predict(X)\n",
    "        return roc_auc_score(y, predictions, multi_class=\"ovr\", average='micro')\n",
    "        \n",
    "    \n",
    "    def fit(self, X: pd.DataFrame, y: pd.Series):\n",
    "        \n",
    "        data = self._split_train_test(X, y)\n",
    "        \n",
    "        model = LGBMClassifier(n_estimators = 10000, **self.lgb_params)\n",
    "        model.fit(data.X_train, data.y_train, \n",
    "                  eval_set=[(data.X_train, data.y_train), (data.X_valid, data.y_valid)],)\n",
    "                #   eval_names = ['train', 'valid'],)\n",
    "                #   eval_metric='cross_entropy',)\n",
    "                #   callbacks=[lightgbm.early_stopping(100), lightgbm.log_evaluation(100)])\n",
    "        \n",
    "        self.model = model\n",
    "    \n",
    "        # auc_train = self.calc_auc(data.X_train, data.y_train)\n",
    "        # auc_test = self.calc_auc(data.X_valid, data.y_valid)\n",
    "        \n",
    "        # print(f\"\\n\\nauc_train = {auc_train:.3f}\\nauc_test = {auc_test:.3f}\\n\")\n",
    "        \n",
    "        self._y_valid = data.y_valid\n",
    "        self._pr_valid = self.predict(data.X_valid)\n",
    "        # self._columns = X.columns\n",
    "        \n",
    "    def fit_with_grid_search(self, X: pd.DataFrame, y: pd.Series, param_grid: dict, rc_params: dict):\n",
    "        \n",
    "        data = self._split_train_test(X, y)\n",
    "        \n",
    "        lg_train = lightgbm.Dataset(data.X_train, label=data.y_train)\n",
    "        lg_valid = lightgbm.Dataset(data.X_valid, label=data.y_valid)\n",
    "        \n",
    "        \n",
    "        grid_search_res = {}\n",
    "\n",
    "        model = LGBMClassifier()\n",
    "\n",
    "        # RandomizedSearchCV, GridSearchCV\n",
    "        grid_search = RandomizedSearchCV(\n",
    "            estimator=model,\n",
    "            param_distributions=param_grid,\n",
    "            scoring='roc_auc',\n",
    "            n_iter=20,\n",
    "            n_jobs=20,\n",
    "            verbose=-1,\n",
    "            **rc_params\n",
    "        )\n",
    "\n",
    "        grid_search.fit(\n",
    "            data.X_train, data.y_train\n",
    "        )\n",
    "        \n",
    "        self.model = grid_search.best_estimator_\n",
    "        \n",
    "        self._y_valid = data.y_valid\n",
    "        self._pr_valid = self.predict(data.X_valid)\n",
    "        self._columns = X.columns\n",
    "\n",
    "        print(f'Best AUC: {grid_search.best_score_}')\n",
    "        print('Best params:')\n",
    "        print(grid_search.best_params_)\n",
    "        \n",
    "        auc_train = self.calc_auc(data.X_train, data.y_train)\n",
    "        auc_test = self.calc_auc(data.X_valid, data.y_valid)\n",
    "        \n",
    "        print(f\"\\n\\nauc_train = {auc_train:.3f}\\nauc_test = {auc_test:.3f}\\n\")\n",
    "\n",
    "    def get_prediction_table(self, num_buck: int=10) -> pd.DataFrame:\n",
    "        \n",
    "        buck_df = pd.DataFrame({'y':self._y_valid, 'pr': self._pr_valid})\n",
    "        # print(buck_df.shape)\n",
    "        buck_df = buck_df.sort_values('pr', ascending=False).reset_index(drop=True)\n",
    "        # print(buck_df.head(50))\n",
    "        buck_df['buck'] = buck_df.index * num_buck // len(buck_df)\n",
    "        # print(buck_df.iloc[200:250].head(50))\n",
    "        buck_df = buck_df.groupby('buck').agg({'pr': ['max'], 'y': ['mean', 'size']})\n",
    "        buck_df.columns = ['max_pr', 'av_target', 'bucket_size']\n",
    "        \n",
    "        return buck_df\n",
    "    \n",
    "    def get_feature_inportance(self) -> pd.DataFrame:\n",
    "        \n",
    "        fi = pd.DataFrame({'fi': self.model.feature_importances_, 'col': self._columns}) \\\n",
    "            .sort_values('fi', ascending=False)\n",
    "        \n",
    "        return fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_lgb_model = LGBModel(lgb_params=lgb_params, test_size=0.2)\n",
    "full_lgb_model.fit(data, labels)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# rnd_forest = RandomForestClassifier(random_state=42, max_features='sqrt', n_estimators= 500, max_depth=13)\n",
    "# rnd_forest.fit(x_train,y_train)\n",
    "# preds=rnd_forest.predict(x_test)\n",
    "# print(x_test[0])\n",
    "# print(preds[0])\n",
    "# conf_mat = confusion_matrix(y_test, preds)X =\n",
    "# df_cm = pd.DataFrame(conf_mat, index=df['Disease'].unique(), columns=df['Disease'].unique())\n",
    "# print('F1-score% =', f1_score(y_test, preds, average='macro')*100, '|', 'Accuracy% =', accuracy_score(y_test, preds)*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
